\chapter{Restricted isometry constants and restricted orthogonality constants}
\section{Definitions and Basic Properties}
Unlike the \emph{\textcolor[rgb]{1,0,0}{coherence, which only takes paires of columns of a matrix into account}}, the restricted isometry constant of \emph{\textcolor[rgb]{1,0,0}{order $s$ involves all $s$-tuples of columns and is therefore more suited to assess the quality of the matrix}}.

\begin{definition}
    \label{def2.1.1}
    The $s$th \emph{restricted isometry constant} $\delta_s = \delta_s(\mathbf{A})$ of a matrix $\mathbf{A} \in \mathbb{C^{m \times N}}$ is the smallest $\delta \geq 0$ such that
    \begin{equation}
        (1-\delta)\|x\|^2_2 \leq \|\mathbf{A}x\|_2^2 \leq (1+\delta)\|x\|^2_2
        \label{eq2.1.1}
    \end{equation}
    for all $s$-sparse vectors $x \in \mathbb{C}^N$. Equivalently, it is given by
    \begin{equation}
        \delta_s = \max\limits_{S \subset [N], card(S) \leq s} \|\mathbf{A}^*_S \mathbf{A}_S - \mathbf{Id}\|_{2 \rightarrow 2}.
        \label{eq2.1.2}
    \end{equation}
\end{definition}

We say that $\mathbf{A}$ satisfies the \emph{restricted isometry property} if \emph{\textcolor[rgb]{1,0,0}{$\delta_s$ is small for reasonably large $s$---the meaning of small $\delta_s$ and large $s$ will be made precise later}}.

Indeed, \cref{eq2.1.2} syas that each column submatrix $\mathbf{A}_S, S \subset [N]$ with $card(S) \leq s$, has all its singular values in the interval $[1-\delta_s,1+\delta_s]$ and is therefore injective when $\delta_s < 1$.

\begin{quote}
    To prove \cref{eq2.1.2} and for the equivalence of \cref{eq2.1.1} and \cref{eq2.1.2} in the complex setting, we start by noticing that \cref{eq2.1.1} is equivalent to 
    \begin{equation*}
        \left|\|\mathbf{A}_S x\|_2^2 - \|x\|_2^2\right| \leq \delta \|x\|_2^2 \quad \text{for all } S \subset [N], card(S) \leq s, \text{and all } x \in \mathbb{C}^S.
    \end{equation*}
    One then observes that, for $x \in \mathbb{C}^S$,
    \begin{equation*}
        \|\mathbf{A}_S x\|_2^2 - \|x\|_2^2 = \left<\mathbf{A}_S x, \mathbf{A}_S x\right> - \left<x, x\right> = \left<\left(\mathbf{A}_S^* \mathbf{A}_S - \mathbf{Id}\right)x, x\right>.
    \end{equation*}
    Since the matrix $\mathbf{A}_S^* \mathbf{A}_S - \mathbf{Id}$ is \textbf{\textcolor[rgb]{1,0,0}{Hermitian}}, we have
    \begin{equation*}
        \max\limits_{x \in \mathbb{C}^S \backslash \{0\}} \dfrac{\left<(\mathbf{A}_S^* \mathbf{A}_S - \mathbf{Id})x,x\right>}{\|x\|_2^2} = \|\mathbf{A}_S^* \mathbf{A}_S - \mathbf{Id}\|_{2 \rightarrow 2},
    \end{equation*}
    so that \cref{eq2.1.1} is equivalent to 
    \begin{equation*}
        \max\limits_{S \subset [N], card(S) \leq s} \|\mathbf{A}_S^* \mathbf{A}_S - \mathbf{Id}\|_{2 \rightarrow 2} \leq \delta.
    \end{equation*}
    This proves the identity \cref{eq2.1.2}, as $\delta_s$ is the smallest such $\delta$.
\end{quote}

\begin{proposition}
    \label{pr2.2}
    If the matrix $A$ has $\ell_2$-normalized columns $a_1,\dots,a_N,i.e.,\|a_j\|_2=1$ for all $j \in [N]$, then
    \begin{equation*}
        \delta_1=0, \qquad \delta_2=\mu, \qquad \delta_s \leq \mu_1(s-1) \leq (s-1)\mu, \quad s \geq 2.
    \end{equation*}
\end{proposition}

\begin{proof}
    The $\ell_2$-normalization of the columns means that $\|\mathbf{A}e_j\|_2^2 = \|e_j\|_2^2$ for all $j \in [N]$, that is to say $\delta_1 = 0$. Next, with $a_1,\dots,a_N$ denoting the columns of the matrix $\mathbf{A}$, we have
    \begin{equation*}
        \delta_2 = \max\limits_{1 \leq i \neq j \leq N} \|\mathbf{A}_{i,j}^*\mathbf{A}_{i,j} - \mathbf{Id}\|_{2 \rightarrow 2}, \qquad \mathbf{A}_{i,j}^*\mathbf{A}_{i,j} = 
        \left[
            \begin{array}{cc}
                1 & \left<a_j,a_i\right> \\
                \left<a_i,a_j\right> &1
            \end{array}
        \right].
    \end{equation*}
    The eigenvalues of the matrix $\mathbf{A}_{i,j}^*\mathbf{A}_{i,j} - \mathbf{Id}$ are $\left|\left<a_i,a_j\right>\right|$ and $-\left|\left<a_i,a_j\right>\right|$, so its operator norm is $\left|\left<a_i,a_j\right>\right|$. Taking the maximum over $1 \leq i \neq i \leq N$ yields the equality $\delta_2 = \mu$. The inequality $\delta_s \leq \mu_1(s-1) \leq (s-1)\mu$ folows from \cref{th1.3}.
\end{proof}

In view of the existence of $m \times m^2$ matrices with coherence $\mu$ equal to $1/\sqrt{m}$ (see \cref{coherence}), this already shows the existence of $m \times m^2$ matrices with restricted isometry constant $\delta_s < 1$ for $s \leq \sqrt{m}$. We will establish that, given $\delta < 1$, there exist $m \times N$ matrices with restricted isometry constant $\delta_s \leq \delta$ for $s \leq cm/\ln(eN/m)$, where $c$ is a constant depending only on $\delta$. \emph{\textcolor[rgb]{1,0,0}{Matrices with a small restricted isometry constant of this optimal order are informally said to satisfy the \textbf{restricted isometry property} and \textbf{uniform uncertainty principle}}}.

A simple but essential observation will be made, which \emph{\textcolor[rgb]{1,0,0}{motivates the related notion of restricted orthogonality constant}}.
\begin{proposition}
    \label{pr2.3}
    Let $\mathbf{u},\mathbf{v} \in \mathbb{C}^N$ be vectors with $\|\mathbf{u}\|_0 \leq s$ and $\|\mathbf{v}\|_0 \leq t$. If $supp(\mathbf{u}) \cap supp(\mathbf{v}) = \cancel{0}$, then
    \begin{equation}
        \label{eq2.3}
        \left|\left<\mathbf{Au}, \mathbf{Av}\right>\right| \leq \delta_{s+t} \|\mathbf{u}\|_2\|\mathbf{v}\|_2.
    \end{equation}
\end{proposition}

\begin{definition}
    \label{def2.4}
    The $(s,t)$-restricted orthogonality constant $\theta_{s,t} = \theta_{s,t}(\mathbf{A})$ of a matrix $\mathbf{A} \in \mathbb{C}^{m \times N}$ is the smallest $\theta \geq 0$ such that
    \begin{equation}
        \label{eq2.4}
        \left|\left<\mathbf{Au}, \mathbf{Av}\right>\right| \leq \theta \|\mathbf{u}\|_2 \|\mathbf{v}\|_2
    \end{equation}
    for all disjointly supported $s$-sparse and $t$-sparse vectors $\mathbf{u,v} \in \mathbb{C}^N$. Equivalently, it is given by 
    \begin{equation}
        \label{eq2.5}
        \theta_{s,t} = \max\left\{\|\mathbf{a}_T^*\mathbf{A}_s\|_{2 \rightarrow 2}, S \cap T = \cancel{0}, card(S) \leq s, card(T) \leq t\right\}.
    \end{equation}
\end{definition}

\begin{proposition}
    \label{pr2.5}
    Restricted isometry constants and restricted orthogonality constants are related by
    \begin{equation*}
        \theta_{s,t} \leq \delta_{s+t} \leq \dfrac{1}{s+t}(s\delta_s + t\delta_t +2 \sqrt{st}\theta_{s,t}).
    \end{equation*}
    The special case $t=s$ gives the inequalities
    \begin{equation*}
        \theta_{s,s} \leq \delta_{2s} \qquad and \qquad \delta_{2s} \leq \delta_s + \theta_{s,s}.
    \end{equation*}
\end{proposition}

Restricted isometry constants and restricted orthogonality constants of high order can be controlled by those of lower order.
\begin{proposition}
    \label{pr2.6}
    For integers $r,s,t \geq 1$ with $t \geq s$,
    \begin{eqnarray*}
        \theta_{t,r} &\leq& \sqrt{\dfrac{t}{s}}\theta_{s,r}, \\
    \theta_t &\leq& \dfrac{t-d}{s}\delta_{2s} + \dfrac{d}{s} \delta_s \qquad d:= \text{gcd}(s,t).
    \end{eqnarray*}
    The special case $t= cs$ gives 
    \[
        \delta_{cs} \leq c \delta_{2s}.
    \]
\end{proposition}
\begin{remark}
    \label{rmk2.7}
    There are other relations enabling to control constants of higher order by constants of lower order
\end{remark}

\begin{theorem}
    \label{th2.8}
    For $\mathbf{A} \in \mathbb{C}^{m \times N}$ and $1 \leq s \leq N$, one has 
    \begin{equation}
        m \geq c \dfrac{s}{\delta_s^2}
        \label{eq2.9}
    \end{equation}
    provided $N \geq Cm$ and $\delta_s \leq \delta_*$, where the constants $c,C$ and $\delta_*$ depend only on each other. For instance, the choices $c = 1/162, C=30$ and $\delta_* = 2/3$ are valid.
\end{theorem}

\begin{proof}
    We set $t := \,s/2\! \geq 1$, and decompose the matrix $\mathbf{A}$ in blocks of size $m \times t$---except possibly the last one which may have less columns---as
    \[
        \mathbf{A} = \left[ \mathbf{A}_1 | \mathbf{A}_2 | \dots| \mathbf{A}_n \right], N \leq nt.
    \]

    From \cref{eq2.1.2} and \cref{eq2.5}, we recall that, for all $i,j \in [n], i \neq i$
    \[
        \|\mathbf{A}_i^*\mathbf{A}_i - \mathbf{Id}\|_{2 \rightarrow 2} \leq \delta_t \leq \delta_s, \qquad \|\mathbf{A}_i^*\mathbf{A}_j\|_{2 \rightarrow 2} \leq \theta_{t,t} \leq \delta_{2t} \leq \delta_s,
    \]
    so that the eigenvalues of $\mathbf{A}_i^*\mathbf{A}_i$ and the singular values of $\mathbf{A}_i^*\mathbf{A}_j$ satisfy
    \[
        1 - \delta_s \leq \lambda_k(\mathbf{A}_i^*\mathbf{A}_i) \leq 1 + \delta_s, \qquad \sigma_k(\mathbf{A}_i^*) \leq \delta_s
    \]
    Let us introduce the matrices 
    \[
        \mathbf{H} := \mathbf{AA}^* \in \mathbb{C}^{m \times m}, \qquad \mathbf{G} := \mathbf{A}^*\mathbf{A} = [\mathbf{A}_i^* \mathbf{A}_i]_{1 \leq i, j\leq n} \in \mathbb{C}^{N \times N}.
    \]
    On the one hand, we have the lower bound
    \begin{equation}
        tr(\mathbf{H}) = tr(\mathbf{G}) = \sum\limits_{i = 1}^n tr(\mathbf{A}_i^* \mathbf{A}_i) = \sum\limits_{i=1}^n \sum\limits_{k=1}^t \lambda_k(\mathbf{A}_i^*\mathbf{A}_i) \geq nt (1- \delta_s).
        \label{eq2.10}
    \end{equation}
    On the other hand, writing $\left<\mathbf{M}_1,\mathbf{M}_2\right>_F = tr(\mathbf{M}_2^* \mathbf{M}_1)$ for the Frobenius inner product of two matrices $\mathbf{M}_1$ and $\mathbf{M}_2$, we have
    \[
        tr(\mathbf{H})^2 = \left<\mathbf{Id}_m, \mathbf{H}\right>_F^2 \leq \|\mathbf{Id}_m\|_F^2 \|\mathbf{H}\|_F^2 = m tr(\mathbf{H}^*\mathbf{H}).
    \]
    Then, by cyclicity of the trace,
    \begin{eqnarray}
        tr(\mathbf{H}^*\mathbf{H}) &=& tr(\mathbf{AA}^*\mathbf{AA}^*) = tr(\mathbf{A}^*\mathbf{AA}^*\mathbf{A}) = tr(\mathbf{GG}^*) \notag \\
        &=& \sum\limits_{i=1}^n tr(\sum\limits_{j=1}^* \mathbf{A}_i^* \mathbf{A}_j \mathbf{A}_j^* \mathbf{A}_i) \notag \\
    &=& \sum\limits_{1 \leq i \neq j \leq n} \sum\limits_{k=1}^t \sigma_k(\mathbf{A}_i^* \mathbf{A}_j)^2 + \sum\limits_{i=1}^n \sum\limits_{k=1} ^t \lambda_k (\mathbf{A}_i^* \mathbf{A}_i)^2 \notag \\
        &\leq& n (n-1) t \delta_s^2 + nt(1+\delta_s)^2. \notag 
    \end{eqnarray}
    The upper bound is derived
    \begin{equation}
        tr(\mathbf{H})^2 \leq m n t \left( (n-1)\delta_s^2 + (1+ \delta_s)^2 \right).
        \label{eq2.11}
    \end{equation}
    Combining the bounds \cref{eq2.10} and \cref{eq2.11} yields
    \[
        m \geq \dfrac{nt(1- \delta_s)^2}{(n-1)\delta_s^2 + (1+\delta_s)^2}.
    \]
    If $(n-1)\delta_s^2 < (1 + \delta_s)^2/5$, we would obtain, using $\delta \leq 2/3$,
    \[
        m > \dfrac{nt(1-\delta_s)^2}{6(1 + \delta_2)^2/5} \geq \dfrac{5(1-\delta_s)^2}{6(1+ \delta_s)^2} N \geq \dfrac{1}{30}N,
    \]
    which contradicts the assumption. We therefore have $(n-1)\delta_s^2 \geq (1+\delta_s)^2 /5$, which yields, using $\delta_s \leq 2/3$ again and $s \leq 3t$,
    \[
        m \geq \dfrac{nt(1-\delta-s)^2}{6(n-1)\delta_s^2} \geq \dfrac{1}{54} \dfrac{t}{\delta_s^2} \geq \dfrac{1}{162} \dfrac{s}{\delta_s^2}.
    \]
    This is the desired result.
\end{proof}

Let us compare the previous lower bound on restricted isometry constants, namely
\begin{equation}
    \delta_s \geq \sqrt{cs/m},
    \label{eq2.12}
\end{equation}
with upper bounds available so far. Precisely, choosing a matrix $\mathbf{A} \in \mathbb{C}^{m \times n}$ with a coherence of optimal order $\mu \leq c/\sqrt{m}$, \cref{pr2.2} implies that
\begin{equation}
    \delta_s \leq (s-1)\mu \leq cs/\sqrt{m}.
    \label{eq2.13}
\end{equation}
There's a significant gap between \cref{eq2.12} and \cref{eq2.13}. In particular, \cref{eq2.13} with the quadratic scaling
\begin{equation}
    m \geq c's^2
    \label{eq2.14}
\end{equation}
allows $\delta_s$ to be small, while this requires under \cref{eq2.12} that $m \geq c's$. However, whether such a condition can be sufficient is unknown at this point. Certain matrices $\mathbf{A} \in \mathbb{R}^{m \times N}$ satisfy $\delta_s \leq \delta$ with high probability for some $\delta > 0$ provided
\begin{equation}
    m \geq C \delta^{-2} s \ln(eN/s).
    \label{eq2.15}
\end{equation}

$\delta_s \leq \delta$ requires $m \geq C_{\delta}s\ln(eN/s)$. Therefore, the lower bound $m \geq c'$ is optimal up to logarighmic factors, and \cref{eq2.9} is optimal regarding the scailing $C_{\delta} = C \delta^{-2}$.

\textbf{Difficulty of Deterministic Constructions of matrices with RIP}. As mensioned, random matrices will be used to obatin the restricted isometry property $\delta_s \leq \delta$ (abbreviated RIP) in the optimal regime \cref{eq2.15} for the number $m$ of mearsurements in terms of the sparsity $s$ and the vector length $N$. Finding deterministic matrices satisfying $\delta_s \leq \delta$ in this regime is a major open problem. Essentially all available estimations of $\delta_s$ for deterministic matrices combine a coherence estimation and \cref{pr2.2} in one form or another. This leads to bounds of the type \cref{eq2.13} and in turn to the quadratic bottleneck \cref{eq2.14}. Thus, \textcolor[rgb]{1,0,0}{the lower bound of \cref{th1.7} in principle prevents such a proof technique to generate improved results}. \emph{\textcolor[rgb]{1,0,0}{The intrinsic difficulty in bounding the restricted isometry constants of explicit matrices $\mathbf{A}$ lies in the basic tool for estimating the eigenvalues of $\mathbf{A}_S^*\mathbf{A}_S-\mathbf{Id}$, namely, Gershgorin's disk theorem \cref{tha.11}}}. Assuming $\ell_2$-normalization of the columns of $\mathbf{A}$ and taking the supremum over all $S \subset [N]$ with card$(S) = s$ leads then to the $\ell_1$-coherence function $\mu_1(s-1)$---this is how we showed the bound $\delta_s \leq \mu_1(s-1)$ of \cref{pr2.2}; see also \cref{th1.3}.

\section{Analysis of Basis Pursuit}

\begin{theorem}
    \label{th2.9}
    Suppose that the $2s$th restricted isometry constant of the matrix $\mathbf{A} \in \mathbb{C}^{m \times N}$ satisfies 
    \begin{equation}
        \delta_{2s} < \frac{1}{3}. 
        \label{eq2.16}
    \end{equation}
    Then every $s$-sparse vector $x \in \mathbb{C}^{N}$ is the unique solution of 
    \[
        \min\limits_{z \in \mathbb{C}^N} \|z\|_1 \qquad \text{subject to } \mathbf{Az} = \mathbf{Ax}.
    \]
\end{theorem}

\begin{lemma}
    \label{lm2.10}
    Given $q > p >0$, if $\mathbf{u} \in \mathbb{C}^t$ satisfy
    \begin{equation}
        \max\limits_{i \in [s]} \left|u_i\right| \leq \min\limits_{j \in [t]} \left|v_j\right|,
        \label{eq2.17}
    \end{equation}
    then 
    \[
        \|\mathbf{u}\|_q \leq \frac{s^{1/q}}{t^{1/p}} \|\mathbf{v}\|_p.
    \]
    The special case $p=1, q=2$, and $t=s$ gives 
    \[
        \|\mathbf{u}\|_2 \leq \frac{1}{\sqrt{s}} \|\mathbf{v}\|_1.
    \]
\end{lemma}

\begin{proof}
    For the first statement, we only need to notice that
    \[
        \frac{\|\mathbf{u}\|_q}{s^{1/q}} = \left[ \frac{1}{s}\sum\limits_{i=1}^s \left|u_i\right|^q \right]^{1/q} \leq \max\limits_{i \in [s]}\left|u_i\right|,
    \]
    \[
        \frac{\|\mathbf{v}\|_p}{t^{1/p}} = \left[ \frac{1}{t} \sum\limits_{j=1}^t \left|v_j\right|^p \right]^{1/p} \geq \min\limits_{j \in [t]} \left|v_{j}\right|,
    \]
    and to use \cref{eq2.17}. The second statement is an immediate consequence.
\end{proof}



\begin{proof} {(\cref{th2.9})}
    According to \cref{th4.5frombook}, it is enough to establish the null space property of order $s$ in the form
    \[
        \|\mathbf{v}_S\|_1 < \frac{1}{2}\|\mathbf{v}\|_1 \quad \text{for all } \mathbf{v} \in ker\ \mathbf{A} \backslash \{0\} \text{ and all } S\subset [N] \text{ with card}(S)=s.
    \]
    This will follow from the stronger statement
    \[
        \|\mathbf{v}_S\|_s \leq \frac{\rho}{2 \sqrt{s}}\|\mathbf{v}\|_1 \quad \text{for all } \mathbf{v} \in ker\ \mathbf{A} \text{ and all } S\subset [N] \text{ with card}(S)=s.
    \]
    where
    \[
        \rho := \frac{2 \delta_{2s}}{1- \delta_{2s}}
    \]
    satisfies $\rho<1$ whenever $\delta_{2s} < 1/3$. Given $\mathbf{v} \in ker\mathbf{A}$, we notice that it is enough to consider an index set $S =: S_0$ of $s$ large absolute entries of the vector $\mathbf{v}$. We partition the complement $\overline{S_0}$ of $S_0$ in $[N]$ as $\overline{S_0} = S_1 \cup S_2 \cup \dots,$ where
    \begin{center}
        $S_1$ : index set of $s$ largest absolute entries of $\mathbf{v}$ in $\overline{S_0}$,\\
        $S_0$ : index set of $s$ largest absolute entries of $\mathbf{v}$ in $\overline{S_0 \cup S_1}$,
    \end{center}
    etc. In view of $\mathbf{v} \in ker\mathbf{A}$, we have $\mathbf{A}(\mathbf{v}_{S_0}) = \mathbf{A}(-\mathbf{v}_{S_1}-\mathbf{v}_{S_2}-\dots)$, so that 
    \begin{eqnarray}
        \|\mathbf{v}_{S_0}\|_2^2 &\leq& \frac{1}{1-\delta_{2s}} \|\mathbf{A}(\mathbf{v}_{S_0})\|_2^2 = \frac{1}{1-\delta_{2s}}\left<\mathbf{A}(-\mathbf{v}_{S_1}), \mathbf{A}(-\mathbf{v}_{S_0}), \mathbf{A}(-\mathbf{v}_{S_1}) + \mathbf{A}(-\mathbf{v}_{S_2})+\dots\right> \notag \\
        &=& \frac{1}{1-\delta_{2s}} \sum\limits_{k \geq 1}\left<\mathbf{A}(\mathbf{v}_{S_0}), \mathbf{A}(-\mathbf{v}_{S_k})\right>.
        \label{eq2.18}
    \end{eqnarray}
    According to \cref{pr2.3}, we also have
    \begin{equation}
        \left<\mathbf{A}(\mathbf{v}_{S_0}), \mathbf{A}(-\mathbf{v}_{S_k})\right> \leq \delta_{2s} \|\mathbf{v}_{S_0}\|_2 \|\mathbf{v}_{S_k}\|_2
        \label{eq2.19}
    \end{equation}
    Substituting \cref{eq2.19} into \cref{eq2.18} and dividing by $\|\mathbf{v}_{S_0}\|_2 > 0$, we obtain
    \[
        \|\mathbf{v}_{S_0}\|_2 \leq \frac{\delta_{2s}}{1-\delta_{2s}} \sum\limits_{k \geq 1} \|\mathbf{v}_{S_k}\|_2 = \frac{\rho}{2} \sum\limits_{k \geq 1} \|\mathbf{v}_{S_k}\|_2.
    \]
    For $k \geq 1$, tht $s$ absolute entries of $\mathbf{v}_{S_k}$ do not exceed the $s$ absolute entries of $\mathbf{v}_{S_{k-1}}$, so that \cref{lm2.10} yields
    \[
        \|\mathbf{v}_{S_k}\|_2 \leq \frac{1}{\sqrt{s}} \|\mathbf{v}_{S_{k-1}}\|_1.
    \]
    We then derive
    \[
        \|\mathbf{v}_{S_0}\|_2 \leq \frac{\rho}{2 \sqrt{s}} \sum\limits_{k \geq 1} \|\mathbf{v}_{S_{k-1}}\|_1 \leq \frac{\rho}{2 \sqrt{s}} \|\mathbf{v}\|_1.
    \]
    This is the desired inequality.
\end{proof}

\begin{mdframed}
    \begin{theorem}
        \label{th4.5frombook}
        Given a matrix $\mathbf{A} \in \mathbb{K}^{m \times N}$, every $s$-sparse vector $x \in \mathbb{K}^N$ is the unique solution of 
        \[
            \min\limits_{z \in \mathbb{C}^N} \|z\|_1 \qquad \text{subject to } \mathbf{A}z = y.
        \]
        with $y = \mathbf{A}x$ if and only if $\mathbf{A}$ satisfies the null space property of order s.
    \end{theorem}
\end{mdframed}

\begin{theorem}
    \label{th2.12}
    Suppose that the $2s$th restricted isometry constant of the matrix $\mathbf{A} \in \mathbb{C}^{m \times N}$ satisfies
    \begin{equation}
        \delta_{2s} < \frac{4}{\sqrt{41}} \approx 0.6246.
        \label{eq2.20}
    \end{equation}
    Then, for any $x \in \mathbb{C}^N$ and $y \in \mathbb{C}^m$ with $\|\mathbf{A}x - y\|_2 \leq \eta$, a solution $x^{\sharp}$ of 
    \[
        \min\limits_{z \in \mathbb{C}^N} \|z\|_1 \qquad \text{subject to } \|\mathbf{A}z - y\|_2 \leq \eta
    \]
    approximates the vector $x$ with errors
    \[
        \|x - x^{\sharp}\|_1 \leq C \sigma_s(x)_1 + D \sqrt{s} \eta,
    \]
    \[
        \|x-x^{\sharp}\|_2 \leq \frac{C}{\sqrt{s}} \sigma_s(x)_1 + D \eta,
    \]
    where the constants $C ,D > 0$ depend only on $\delta_{2s}$.
\end{theorem}
\begin{theorem}
    \label{th2.13}
    If the $2s$th restricted isometry constant of $\mathbf{A} \in \mathbb{C}^{m\times N}$ obeys \cref{eq2.20}, then the matrix $\mathbf{A}$ satisfies the $\ell_2$-robust null space property of order $s$ with constants $0<p<1$ and $\tau > 0$ depending only on $\delta_{2s}$. 
\end{theorem}

\begin{lemma}
    \label{lm2.14}
    For $a_1 \geq a_2 \geq \dots \geq a_s \geq 0$.
    \[
        \sqrt{a_1^2 + \dots +a_s^2} \leq \frac{a_1 + \dots + a_s}{\sqrt{s}} + \frac{\sqrt{s}}{4}a_s \leq 1.
    \]
\end{lemma}














